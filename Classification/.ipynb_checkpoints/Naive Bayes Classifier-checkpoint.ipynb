{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix   \n",
    "import nltk\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import gensim\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/cleaned_hotelreviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove NaN and covert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data_lower = [[word.lower() for word in d.split()] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and check the result with unprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert to BOW\n",
    "dictionary = corpora.Dictionary(data_lower['sentence'])\n",
    "data_stem['reviews'] = [dictionary.doc2bow(doc) for doc in data_stem['reviews']]\n",
    "data_stem['reviews'] = [{id:1 for (id, tf_value) in vec} for vec in data_stem['reviews']]\n",
    "\n",
    "# Convert to tuple\n",
    "tuples_list = list(data.itertuples(index=False, name=None))\n",
    "\n",
    "# Fit into model\n",
    "random.shuffle(tuples_list)\n",
    "fold_count = 10\n",
    "kf = KFold(n_splits = fold_count)\n",
    "total = 0\n",
    "count = 1\n",
    "\n",
    "for train, test in kf.split(tuples_list):\n",
    "    train_data = np.array(tuples_list)[train]\n",
    "    test_data = np.array(tuples_list)[test]\n",
    "    print(\"train size:\", len(train_data), \"test size:\", len(test_data))\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_data)\n",
    "    print(\"Fold\", count, \":\", nltk.classify.accuracy(classifier, test_data))\n",
    "    total += nltk.classify.accuracy(classifier, test_data)\n",
    "    count+=1\n",
    "average_accuracy = total/fold_count\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "\n",
    "# Confusion Matrix\n",
    "test_result = []\n",
    "gold_result = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    test_result.append(classifier.classify(test_data[i][0]))\n",
    "    gold_result.append(test_data[i][1])\n",
    "\n",
    "print('\\nClasification report:\\n', classification_report(gold_result, test_result))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(gold_result, test_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove nan and Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "stop_list = stopwords.words('english')\n",
    "data['reviews'] = data['reviews'].apply(lambda x: [word for word in x.split() if word not in stop_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove single word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviews'] = data['reviews'].apply(lambda x: x if len(x) > 1 else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data['reviews'] != '[]'] has error has convert list to string\n",
    "cleaned_data = data[data.astype(str)['reviews'] != '[]']\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "# data_stem = cleaned_data.copy(deep=True)\n",
    "cleaned_data['stem_reviews'] = cleaned_data['reviews'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lemetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "# data_lemmatize = cleaned_data.copy(deep=True)\n",
    "cleaned_data['lemma_reviews'] = cleaned_data['reviews'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Gensim to convert to dictionary and prepare data for training\n",
    "1. Convert reviews to dictionary\n",
    "2. Convert the reviews dictionary into TF vectors \n",
    "3. Tag a number to the word based on each review TF vector\n",
    "4. Tag the dictionary with either positive or negative based on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1...\n",
      "1         [(4, 1), (40, 1), (57, 1), (81, 3), (120, 1), ...\n",
      "2         [(1, 1), (17, 2), (29, 1), (39, 3), (51, 2), (...\n",
      "3         [(3, 1), (14, 3), (43, 2), (60, 1), (81, 3), (...\n",
      "4         [(51, 2), (241, 1), (242, 1), (243, 1), (244, ...\n",
      "                                ...                        \n",
      "834105                                 [(255, 1), (288, 1)]\n",
      "834106    [(3, 1), (21, 2), (98, 1), (200, 1), (434, 1),...\n",
      "834108      [(21, 1), (44, 1), (70, 1), (159, 1), (288, 1)]\n",
      "834109    [(81, 1), (151, 1), (231, 1), (320, 1), (382, ...\n",
      "834110                                 [(200, 1), (461, 1)]\n",
      "Name: reviews, Length: 791439, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Stemming \n",
    "dictionary = corpora.Dictionary(cleaned_data['stem_reviews'])\n",
    "cleaned_data['stem_reviews'] = [dictionary.doc2bow(doc) for doc in cleaned_data['stem_reviews']]\n",
    "\n",
    "# Lemmatize\n",
    "dictionary = corpora.Dictionary(cleaned_data['lemma_reviews'])\n",
    "cleaned_data['lemma_reviews'] = [dictionary.doc2bow(doc) for doc in cleaned_data['lemma_reviews']]\n",
    "\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_list = cleaned_data['stem_reviews'].values.T.tolist()\n",
    "tfidf = models.TfidfModel(cleaned_data_list)\n",
    "cleaned_data_with_tfidf = [tfidf[vec] for vec in cleaned_data_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.phrases.Phrases(dataset, min_count=3, threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = gensim.models.phrases.Phrases(bigram[dataset], threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 6), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 2), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 3), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 2), (45, 2), (46, 1), (47, 1), (48, 1), (49, 2), (50, 1), (51, 3), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 3), (59, 1), (60, 2), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 3), (67, 1), (68, 1), (69, 2), (70, 1), (71, 2), (72, 2), (73, 1), (74, 3), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 13), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 2), (99, 1), (100, 1), (101, 1), (102, 2), (103, 1), (104, 1), (105, 1), (106, 3), (107, 1), (108, 1), (109, 1), (110, 1), (111, 2), (112, 1), (113, 2), (114, 2), (115, 1), (116, 1), (117, 3), (118, 1), (119, 1)], [(4, 1), (40, 1), (57, 1), (81, 3), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(data_stem_list[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stem['reviews'] = [{id:1 for (id, tf_value) in vec} for vec in data_stem['reviews']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split the dataframe and conver into tuples (Not use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = data_stem\n",
    "msk = np.random.rand(len(train_test_data)) < 0.8\n",
    "train = train_test_data[msk]\n",
    "test = train_test_data[~msk]\n",
    "\n",
    "tuples_train_list =list(train.itertuples(index=False, name=None))\n",
    "tuples_test_list = list(test.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({46: 1, 60: 1, 67: 1, 68: 1, 199: 1, 225: 1, 260: 1}, 'negative')\n"
     ]
    }
   ],
   "source": [
    "print(tuples_test_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataframe into a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1, 45: 1, 46: 1, 47: 1, 48: 1, 49: 1, 50: 1, 51: 1, 52: 1, 53: 1, 54: 1, 55: 1, 56: 1, 57: 1, 58: 1, 59: 1, 60: 1, 61: 1, 62: 1, 63: 1, 64: 1, 65: 1, 66: 1, 67: 1, 68: 1, 69: 1, 70: 1, 71: 1, 72: 1, 73: 1, 74: 1, 75: 1, 76: 1, 77: 1, 78: 1, 79: 1, 80: 1, 81: 1, 82: 1, 83: 1, 84: 1, 85: 1, 86: 1, 87: 1, 88: 1, 89: 1, 90: 1, 91: 1, 92: 1, 93: 1, 94: 1, 95: 1, 96: 1, 97: 1, 98: 1, 99: 1, 100: 1, 101: 1, 102: 1, 103: 1, 104: 1, 105: 1, 106: 1, 107: 1, 108: 1, 109: 1, 110: 1, 111: 1, 112: 1, 113: 1, 114: 1, 115: 1, 116: 1, 117: 1, 118: 1, 119: 1}, 'negative')\n"
     ]
    }
   ],
   "source": [
    "data = data_stem\n",
    "tuples_list = list(data.itertuples(index=False, name=None))\n",
    "print(tuples_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the train data into nltk classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 712295 test size: 79144\n",
      "Fold 1 : 0.9111998382694835\n",
      "train size: 712295 test size: 79144\n",
      "Fold 2 : 0.913625796017386\n",
      "train size: 712295 test size: 79144\n",
      "Fold 3 : 0.9122611947841909\n",
      "train size: 712295 test size: 79144\n",
      "Fold 4 : 0.9107576063883555\n",
      "train size: 712295 test size: 79144\n",
      "Fold 5 : 0.911920044475892\n",
      "train size: 712295 test size: 79144\n",
      "Fold 6 : 0.9121222076215506\n",
      "train size: 712295 test size: 79144\n",
      "Fold 7 : 0.9123749115536238\n",
      "train size: 712295 test size: 79144\n",
      "Fold 8 : 0.9137142423936117\n",
      "train size: 712295 test size: 79144\n",
      "Fold 9 : 0.9127286970585262\n",
      "train size: 712296 test size: 79143\n",
      "Fold 10 : 0.9138521410611172\n",
      "Average accuracy: 0.9124556679623737\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(tuples_list)\n",
    "fold_count = 10\n",
    "kf = KFold(n_splits = fold_count)\n",
    "total = 0\n",
    "count = 1\n",
    "\n",
    "for train, test in kf.split(tuples_list):\n",
    "    train_data = np.array(tuples_list)[train]\n",
    "    test_data = np.array(tuples_list)[test]\n",
    "    print(\"train size:\", len(train_data), \"test size:\", len(test_data))\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_data)\n",
    "    print(\"Fold\", count, \":\", nltk.classify.accuracy(classifier, test_data))\n",
    "    total += nltk.classify.accuracy(classifier, test_data)\n",
    "    count+=1\n",
    "average_accuracy = total/fold_count\n",
    "print(\"Average accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90     34504\n",
      "    positive       0.93      0.92      0.92     44639\n",
      "\n",
      "    accuracy                           0.91     79143\n",
      "   macro avg       0.91      0.91      0.91     79143\n",
      "weighted avg       0.91      0.91      0.91     79143\n",
      "\n",
      "\n",
      "Confussion matrix:\n",
      " [[31315  3189]\n",
      " [ 3629 41010]]\n"
     ]
    }
   ],
   "source": [
    "test_result = []\n",
    "gold_result = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    test_result.append(classifier.classify(test_data[i][0]))\n",
    "    gold_result.append(test_data[i][1])\n",
    "\n",
    "print('\\nClasification report:\\n', classification_report(gold_result, test_result))\n",
    "print('\\nConfussion matrix:\\n',confusion_matrix(gold_result, test_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with unseen input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter reviews :awesome view and food\n",
      "[{108: 1, 673: 1, 12951: 1}]\n",
      "Review outcome: positive\n"
     ]
    }
   ],
   "source": [
    "test = input(\"Enter reviews :\")\n",
    "test = test.split()\n",
    "# test = test[word for word in test if word not in stop_list]\n",
    "test = dictionary.doc2bow(test)\n",
    "test = [{id:1 for (id, tf_value) in test}]\n",
    "print(test)\n",
    "print(\"Review outcome:\", classifier.classify(test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
