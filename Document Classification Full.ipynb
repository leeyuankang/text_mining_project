{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries # \n",
    "import pandas as pd \n",
    "import nltk as nltk\n",
    "import  xgboost, numpy, string\n",
    "import datetime as dt\n",
    "import re as re\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions # \n",
    "\n",
    "# Timer to check execution timing for each function call # \n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = dt.datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((dt.datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "def stem(array):\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in array]\n",
    "\n",
    "def lemmetize(array):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    return [lemmatizer.lemmatize(w) for w in array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Data Prep # \n",
    "df = pd.read_csv(\"data/cleaned_hotelreviews_short.csv\")\n",
    "\n",
    "# Drop rows with null comments # \n",
    "df = df.dropna(subset=['reviews'])\n",
    "\n",
    "# Make words case-insensitive # \n",
    "df = df.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Accuracy:  0.945\n",
      "Logistic Regression Accuracy:  0.95\n",
      "SVM Accuracy:  0.76\n",
      "Random Forest Accuracy:  0.915\n",
      "Naive Bayes Accuracy:  0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Run baseline models based on Count Vector # \n",
    "\n",
    "# Train - Test Split # \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['reviews'], df['class'], train_size=0.8, random_state = 3000)\n",
    "\n",
    "# Label encode target variable # \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "# Create Count Vector #  \n",
    "count_vector = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vector.fit(df['reviews'])\n",
    "\n",
    "# Transform training and validation data # \n",
    "xtrain_count = count_vector.transform(train_x)\n",
    "xvalid_count = count_vector.transform(valid_x)\n",
    "\n",
    "# XG Boost on Unprocessed Data # \n",
    "model = xgboost.XGBClassifier().fit(xtrain_count.tocsc(), train_y)\n",
    "predictions = model.predict(xvalid_count.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_y)\n",
    "print(\"XGBoost Classifier Accuracy: \", accuracy)\n",
    "\n",
    "# Logistic Regression on Unprocessed Data # \n",
    "model = linear_model.LogisticRegression().fit(xtrain_count, train_y)\n",
    "predictions = model.predict(xvalid_count)\n",
    "accuracy = metrics.accuracy_score(predictions, valid_y)\n",
    "print(\"Logistic Regression Accuracy: \", accuracy)\n",
    "\n",
    "# SMV on Unprocessed Data # \n",
    "model = svm.SVC().fit(xtrain_count, train_y)\n",
    "predictions = model.predict(xvalid_count)\n",
    "accuracy = metrics.accuracy_score(predictions, valid_y)\n",
    "print(\"SVM Accuracy: \", accuracy)\n",
    "\n",
    "# Random Forest on Unprocessed Data # \n",
    "model  = ensemble.RandomForestClassifier().fit(xtrain_count, train_y)\n",
    "predictions = model.predict(xvalid_count)\n",
    "accuracy = metrics.accuracy_score(predictions, valid_y)\n",
    "print(\"Random Forest Accuracy: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Unprocessed Data # \n",
    "model = naive_bayes.MultinomialNB().fit(xtrain_count, train_y)\n",
    "predictions = model.predict(xvalid_count)\n",
    "accuracy = metrics.accuracy_score(predictions, valid_y)\n",
    "print(\"Naive Bayes Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Data Prep on two best models # \n",
    "\n",
    "# Remove punctuations if any # \n",
    "df[\"words_only\"] = df['reviews'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# Remove stop words # \n",
    "stop_list = stopwords.words('english')\n",
    "df['reviews'] = df['reviews'].apply(lambda x: [word for word in x.split() if word not in stop_list])\n",
    "\n",
    "# Remove single words # \n",
    "df['reviews'] = df['reviews'].apply(lambda x: x if len(x) > 1 else [])\n",
    "\n",
    "# Drop rows where reviews == [] # \n",
    "df = df[df.reviews.str.len()>0]\n",
    "\n",
    "# Tokenization with NLTK # \n",
    "df['tokenized'] = df['words_only'].apply(nltk.word_tokenize)\n",
    "\n",
    "# Stemming with NLTK # \n",
    "df['stemmed'] = df['tokenized'].apply(stem)\n",
    "\n",
    "# Turn arrays for each row in df['stemmed'] into a string #: Needed to run SkLearn Lib\n",
    "df['stemmed'] = df['stemmed'].apply(\" \".join)\n",
    "\n",
    "# Lemmetisation # \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "df['lemmetized'] = df['tokenized'].apply(lemmetize)\n",
    "\n",
    "# Turn arrays for each row in df['lemmetized'] into a string #: Needed to run SkLearn Lib\n",
    "df['lemmetized'] = df['lemmetized'].apply(\" \".join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Test Split for Stemmed Words # \n",
    "train_stemx, valid_stemx, train_stemy, valid_stemy = model_selection.train_test_split(df['stemmed'], df['class'], train_size=0.8, random_state = 3000)\n",
    "\n",
    "# Label encode target variable [STEMMED] # \n",
    "train_stemy = encoder.fit_transform(train_stemy)\n",
    "valid_stemy = encoder.fit_transform(valid_stemy)\n",
    "\n",
    "# Train - Test Split for Lemmetized Words # \n",
    "train_lemx, valid_lemx, train_lemy, valid_lemy = model_selection.train_test_split(df['lemmetized'], df['class'], train_size=0.8, random_state = 3000)\n",
    "\n",
    "# Label encode target variable [LEMMETIZED] # \n",
    "train_lemy = encoder.fit_transform(train_lemy)\n",
    "valid_lemy = encoder.fit_transform(valid_lemy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_____________' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-ab6b920533a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Model 1 #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_____________\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain_count_stem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_stemy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvalid_count_stem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_stemy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_____________' is not defined"
     ]
    }
   ],
   "source": [
    "# Best Models [STEMMED] # \n",
    "\n",
    "# Create Count Vector [STEMMED] #  \n",
    "count_vector.fit(df['stemmed'])\n",
    "xtrain_count_stem = count_vector.transform(train_stemx)\n",
    "xvalid_count_stem = count_vector.transform(valid_stemx)\n",
    "\n",
    "# Model 1 # \n",
    "model = _____________.fit(xtrain_count_stem.tocsc(), train_stemy)\n",
    "predictions = model.predict(xvalid_count_stem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_stemy)\n",
    "print(\"Model 1: \", accuracy)\n",
    "\n",
    "# Model 2 # \n",
    "model = _____________.fit(xtrain_count_stem.tocsc(), train_stemy)\n",
    "predictions = model.predict(xvalid_count_stem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_stemy)\n",
    "print(\"Model 2: \", accuracy)\n",
    "\n",
    "# Ngram Level TF-IDF #: Matrix represents tf-idf scores of unigram (all terms are separate)\n",
    "tfidf_unigram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,1), max_features=5000)\n",
    "tfidf_bigram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,2), max_features=5000)\n",
    "tfidf_trigram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(3,3), max_features=5000)\n",
    "tfidf_quadgram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(4,4), max_features=5000)\n",
    "\n",
    "# Unigram [STEMMED] # \n",
    "tfidf_unigram.fit(df['stemmed'])\n",
    "xtrain_tfidf_unigram_stem = tfidf_unigram.transform(train_stemx)\n",
    "xvalid_tfidf_unigram_stem = tfidf_unigram.transform(valid_stemx)\n",
    "\n",
    "# Model 1 # \n",
    "model = _____________.fit(xtrain_tfidf_unigram_stem.tocsc(), train_stemy)\n",
    "predictions = model.predict(xvalid_tfidf_unigram_stem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_stemy)\n",
    "print(\"Model 1: \", accuracy)\n",
    "\n",
    "# Model 2 # \n",
    "model = _____________.fit(xtrain_tfidf_unigram_stem.tocsc(), train_stemy)\n",
    "predictions = model.predict(xvalid_tfidf_unigram_stem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_stemy)\n",
    "print(\"Model 2: \", accuracy)\n",
    "\n",
    "# Bigram [STEMMED] # \n",
    "tfidf_bigram.fit(df['stemmed'])\n",
    "xtrain_tfidf_bigram_stem = tfidf_bigram.transform(train_stemx)\n",
    "xvalid_tfidf_bigram_stem = tfidf_bigram.transform(valid_stemx)\n",
    "\n",
    "# Model 1 # \n",
    "model = _____________.fit(xtrain_tfidf_bigram_stem.tocsc(), train_stemy)\n",
    "predictions = model.predict(xvalid_tfidf_bigram_stem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_stemy)\n",
    "print(\"Model 1: \", accuracy)\n",
    "\n",
    "# Model 2 # \n",
    "model = _____________.fit(xtrain_tfidf_bigram_stem.tocsc(), train_stemy)\n",
    "predictions = model.predict(xvalid_tfidf_bigram_stem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_stemy)\n",
    "print(\"Model 2: \", accuracy)\n",
    "\n",
    "# Trigram [STEMMED] # \n",
    "tfidf_trigram.fit(df['stemmed'])\n",
    "xtrain_tfidf_trigram_stem = tfidf_trigram.transform(train_stemx)\n",
    "xvalid_tfidf_trigram_stem = tfidf_trigram.transform(valid_stemx)\n",
    "\n",
    "# Model 1 # \n",
    "model = _____________.fit(xtrain_tfidf_trigram_stem.tocsc(), train_stemy)\n",
    "predictions = model.predict(xvalid_tfidf_trigram_stem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_stemy)\n",
    "print(\"Model 1: \", accuracy)\n",
    "\n",
    "# Model 2 # \n",
    "model = _____________.fit(xtrain_tfidf_bigram_stem.tocsc(), train_stemy)\n",
    "predictions = model.predict(xvalid_tfidf_bigram_stem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_stemy)\n",
    "print(\"Model 2: \", accuracy)\n",
    "\n",
    "# Quadgram [STEMMED] # \n",
    "tfidf_quadgram.fit(df['stemmed'])\n",
    "xtrain_tfidf_quadgram_stem = tfidf_quadgram.transform(train_stemx)\n",
    "xvalid_tfidf_quadgram_stem = tfidf_quadgram.transform(valid_stemx)\n",
    "\n",
    "# Model 1 # \n",
    "model = _____________.fit(xtrain_tfidf_quadgram_stem.tocsc(), train_stemy)\n",
    "predictions = model.predict(xvalid_tfidf_quadgram_stem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_stemy)\n",
    "print(\"Model 1: \", accuracy)\n",
    "\n",
    "# Model 2 # \n",
    "model = _____________.fit(xtrain_tfidf_quadgram_stem.tocsc(), train_stemy)\n",
    "predictions = model.predict(xvalid_tfidf_quadgram_stem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_stemy)\n",
    "print(\"Model 2: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_____________' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-e8ea5be3b727>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Model 1 #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_____________\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain_count_lem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_lemy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvalid_count_lem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_lemy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_____________' is not defined"
     ]
    }
   ],
   "source": [
    "# Best Models [LEMMETIZED] # \n",
    "\n",
    "# Create Count Vector [LEMMETIZED] #  \n",
    "count_vector.fit(df['lemmetized'])\n",
    "xtrain_count_lem = count_vector.transform(train_lemx)\n",
    "xvalid_count_lem = count_vector.transform(valid_lemx)\n",
    "\n",
    "# Model 1 # \n",
    "model = _____________.fit(xtrain_count_lem.tocsc(), train_lemy)\n",
    "predictions = model.predict(xvalid_count_lem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_lemy)\n",
    "print(\"Model 1: \", accuracy)\n",
    "\n",
    "# Model 2 # \n",
    "model = _____________.fit(xtrain_count_lem.tocsc(), train_lemy)\n",
    "predictions = model.predict(xvalid_count_lem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_lemy)\n",
    "print(\"Model 2: \", accuracy)\n",
    "\n",
    "# Ngram Level TF-IDF #: Matrix represents tf-idf scores of unigram (all terms are separate)\n",
    "tfidf_unigram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,1), max_features=5000)\n",
    "tfidf_bigram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,2), max_features=5000)\n",
    "tfidf_trigram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(3,3), max_features=5000)\n",
    "tfidf_quadgram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(4,4), max_features=5000)\n",
    "\n",
    "# Unigram [LEMMETIZED] # \n",
    "tfidf_unigram.fit(df['lemmetized'])\n",
    "xtrain_tfidf_unigram_lem = tfidf_unigram.transform(train_lemx)\n",
    "xvalid_tfidf_unigram_lem = tfidf_unigram.transform(valid_lemx)\n",
    "\n",
    "# Model 1 # \n",
    "model = _____________.fit(xtrain_tfidf_unigram_lem.tocsc(), train_lemy)\n",
    "predictions = model.predict(xvalid_tfidf_unigram_lem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_lemy)\n",
    "print(\"Model 1: \", accuracy)\n",
    "\n",
    "# Model 2 # \n",
    "model = _____________.fit(xtrain_tfidf_unigram_lem.tocsc(), train_lemy)\n",
    "predictions = model.predict(xvalid_tfidf_unigram_lem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_lemy)\n",
    "print(\"Model 2: \", accuracy)\n",
    "\n",
    "# Bigram [LEMMETIZED] # \n",
    "tfidf_bigram.fit(df['lemmetized'])\n",
    "xtrain_tfidf_bigram_lem = tfidf_bigram.transform(train_lemx)\n",
    "xvalid_tfidf_bigram_lem = tfidf_bigram.transform(valid_lemx)\n",
    "\n",
    "# Model 1 # \n",
    "model = _____________.fit(xtrain_tfidf_bigram_lem.tocsc(), train_lemy)\n",
    "predictions = model.predict(xvalid_tfidf_bigram_lem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_lemy)\n",
    "print(\"Model 1: \", accuracy)\n",
    "\n",
    "# Model 2 # \n",
    "model = _____________.fit(xtrain_tfidf_bigram_lem.tocsc(), train_lemy)\n",
    "predictions = model.predict(xvalid_tfidf_bigram_lem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_lemy)\n",
    "print(\"Model 2: \", accuracy)\n",
    "\n",
    "# Trigram [LEMMETIZED] # \n",
    "tfidf_trigram.fit(df['lemmetized'])\n",
    "xtrain_tfidf_trigram_lem = tfidf_trigram.transform(train_lemx)\n",
    "xvalid_tfidf_trigram_lem = tfidf_trigram.transform(valid_lemx)\n",
    "\n",
    "# Model 1 # \n",
    "model = _____________.fit(xtrain_tfidf_trigram_lem.tocsc(), train_lemy)\n",
    "predictions = model.predict(xvalid_tfidf_trigram_lem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_lemy)\n",
    "print(\"Model 1: \", accuracy)\n",
    "\n",
    "# Model 2 # \n",
    "model = _____________.fit(xtrain_tfidf_trigram_lem.tocsc(), train_lemy)\n",
    "predictions = model.predict(xvalid_tfidf_trigram_lem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_lemy)\n",
    "print(\"Model 2: \", accuracy)\n",
    "\n",
    "# Quadgram [LEMMETIZED] # \n",
    "tfidf_quadgram.fit(df['lemmetized'])\n",
    "xtrain_tfidf_quadgram_lem = tfidf_quadgram.transform(train_lemx)\n",
    "xvalid_tfidf_quadgram_lem = tfidf_quadgram.transform(valid_lemx)\n",
    "\n",
    "# Model 1 # \n",
    "model = _____________.fit(xtrain_tfidf_quadgram_lem.tocsc(), train_lemy)\n",
    "predictions = model.predict(xvalid_tfidf_quadgram_lem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_lemy)\n",
    "print(\"Model 1: \", accuracy)\n",
    "\n",
    "# Model 2 # \n",
    "model = _____________.fit(xtrain_tfidf_quadgram_lem.tocsc(), train_lemy)\n",
    "predictions = model.predict(xvalid_tfidf_quadgram_lem.tocsc())\n",
    "accuracy = metrics.accuracy_score(predictions, valid_lemy)\n",
    "print(\"Model 2: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
